{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e0ed5fe",
   "metadata": {},
   "source": [
    "# Triplet Distil Net Embedding Generator\n",
    "\n",
    "**Note:** In this notebook we can experiment with \n",
    "\n",
    "- Embedding Sizes\n",
    "- Custom Loss Functions\n",
    "- Epochs and Learning Rate\n",
    "- contact finetuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fde316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import random\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3b3879",
   "metadata": {},
   "source": [
    "# Semi-Hard Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a7606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplets_from_folders(s1_dir, s2_dir, split=(0.7, 0.15, 0.15), seed=42, triplets_per_id=2):\n",
    "    \"\"\"\n",
    "    Generate multiple triplets per identity (anchor, positive, negative) from s1, s2 directories.\n",
    "    Returns dict of train/val/test triplet lists.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    s1_images = sorted(glob.glob(os.path.join(s1_dir, \"*\")))\n",
    "    s2_images = sorted(glob.glob(os.path.join(s2_dir, \"*\")))\n",
    "\n",
    "    # could change depending on how you've named your dataset\n",
    "    def basename_noext(p): return os.path.splitext(os.path.basename(p))[0]\n",
    "    id_to_paths = {}\n",
    "    for p in s1_images:\n",
    "        id_to_paths[basename_noext(p)] = [p, None]\n",
    "    for p in s2_images:\n",
    "        id_ = basename_noext(p)\n",
    "        if id_ in id_to_paths:\n",
    "            id_to_paths[id_][1] = p\n",
    "\n",
    "    valid_ids = [k for k, v in id_to_paths.items() if v[0] and v[1]]\n",
    "    valid_ids.sort()\n",
    "    print(f\"Found {len(valid_ids)} identities with images in both s1 and s2\")\n",
    "\n",
    "    triplets = []\n",
    "    for anchor_id in valid_ids:\n",
    "        anchor = id_to_paths[anchor_id][0]\n",
    "        positive = id_to_paths[anchor_id][1]\n",
    "        neg_ids = [i for i in valid_ids if i != anchor_id]\n",
    "\n",
    "        for _ in range(triplets_per_id):\n",
    "            negative_id = random.choice(neg_ids)\n",
    "            negative = id_to_paths[negative_id][1]\n",
    "            triplets.append((anchor, positive, negative))\n",
    "\n",
    "    random.shuffle(triplets)\n",
    "\n",
    "    n = len(triplets)\n",
    "    n_train = int(split[0] * n)\n",
    "    n_val = int(split[1] * n)\n",
    "    train_triplets = triplets[:n_train]\n",
    "    val_triplets = triplets[n_train:n_train+n_val]\n",
    "    test_triplets = triplets[n_train+n_val:]\n",
    "\n",
    "    print(f\"Total triplets: {len(triplets)} -> train {len(train_triplets)}, val {len(val_triplets)}, test {len(test_triplets)}\")\n",
    "    return {\"train\": train_triplets, \"val\": val_triplets, \"test\": test_triplets}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b40e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# could change depending on how you've named your dataset\n",
    "def get_last_two_parts(path):\n",
    "    \"\"\"Return the last two components of a path as a string.\"\"\"\n",
    "    parts = os.path.normpath(path).split(os.sep)\n",
    "    return os.path.join(*parts[-2:])\n",
    "\n",
    "class TripletDatasetWithTeacher(Dataset):\n",
    "    \"\"\"\n",
    "    triplets: list of tuples (anchor_path, positive_path, negative_path)\n",
    "    teacher_embeddings: np.array of shape (num_images, emb_dim)\n",
    "        Order must match s1/s2 dirs: even=s1, odd=s2\n",
    "    \"\"\"\n",
    "    def __init__(self, triplets, s1_dir, s2_dir, teacher_embeddings, transform=None):\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "        self.teacher_embeddings = teacher_embeddings\n",
    "        s1_paths = sorted(glob.glob(os.path.join(s1_dir, \"*\")))\n",
    "        s2_paths = sorted(glob.glob(os.path.join(s2_dir, \"*\")))\n",
    "\n",
    "        self.path_to_idx = {}\n",
    "        for i, path in enumerate(s1_paths):\n",
    "            self.path_to_idx[get_last_two_parts(path)] = 2*i  # even idx for s1\n",
    "        for i, path in enumerate(s2_paths):\n",
    "            self.path_to_idx[get_last_two_parts(path)] = 2*i + 1  # odd idx for s2\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a_path, p_path, n_path = self.triplets[idx]\n",
    "\n",
    "        # Load images\n",
    "        anchor = Image.open(a_path)\n",
    "        positive = Image.open(p_path)\n",
    "        negative = Image.open(n_path)\n",
    "\n",
    "        anchor = Image.open(a_path).convert('L')  \n",
    "        positive = Image.open(p_path).convert('L')\n",
    "        negative = Image.open(n_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        # Fetch teacher embeddings\n",
    "        key_a = get_last_two_parts(a_path)\n",
    "        key_p = get_last_two_parts(p_path)\n",
    "        key_n = get_last_two_parts(n_path)\n",
    "\n",
    "        t_a = torch.tensor(self.teacher_embeddings[self.path_to_idx[key_a]], dtype=torch.float32)\n",
    "        t_p = torch.tensor(self.teacher_embeddings[self.path_to_idx[key_p]], dtype=torch.float32)\n",
    "        t_n = torch.tensor(self.teacher_embeddings[self.path_to_idx[key_n]], dtype=torch.float32)\n",
    "\n",
    "        # L2-normalize\n",
    "        t_a = F.normalize(t_a, dim=0)\n",
    "        t_p = F.normalize(t_p, dim=0)\n",
    "        t_n = F.normalize(t_n, dim=0)\n",
    "\n",
    "        return anchor, positive, negative, t_a, t_p, t_n\n",
    "    \n",
    "class TripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    triplets: list of tuples (anchor_path, positive_path, negative_path)\n",
    "    \"\"\"\n",
    "    def __init__(self, triplets, transform=None):\n",
    "        self.triplets = triplets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        a_path, p_path, n_path = self.triplets[idx]\n",
    "\n",
    "        anchor = Image.open(a_path) \n",
    "        positive = Image.open(p_path)\n",
    "        negative = Image.open(n_path)\n",
    "\n",
    "        anchor = Image.open(a_path).convert('L') \n",
    "        positive = Image.open(p_path).convert('L')\n",
    "        negative = Image.open(n_path).convert('L')\n",
    "\n",
    "        if self.transform:\n",
    "            anchor = self.transform(anchor)\n",
    "            positive = self.transform(positive)\n",
    "            negative = self.transform(negative)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "\n",
    "# Transforms (strong but safe for ridge details)\n",
    "def get_train_transforms(img_size=512):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.RandomRotation(degrees=15, fill=0)\n",
    "        ], p=0.9),\n",
    "        transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.05,0.05))], p=0.6),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3, sigma=(0.1,1.0))], p=0.2),\n",
    "        transforms.RandomApply([transforms.ColorJitter(brightness=0.05, contrast=0.05)], p=0.5),\n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n",
    "\n",
    "def get_eval_transforms(img_size=512):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6276d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build triplets list: (anchor, positive, negative)\n",
    "s1_dir = \"<DIRNAME>\"\n",
    "s2_dir = \"<DIRNAME>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c5c28",
   "metadata": {},
   "source": [
    "## TripletDistilNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03dda380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletNet(nn.Module):\n",
    "    def __init__(self, embedding_dim=256, pretrained=False):\n",
    "        super().__init__()\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.backbone = nn.Sequential(\n",
    "            resnet.conv1,\n",
    "            resnet.bn1,\n",
    "            resnet.relu,\n",
    "            resnet.maxpool,\n",
    "            resnet.layer1,\n",
    "            resnet.layer2,\n",
    "            resnet.layer3,\n",
    "            resnet.layer4,\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(256, embedding_dim)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.head(x)\n",
    "        x = F.normalize(x, p=2, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, anchor, positive, negative):\n",
    "        e_a = self.forward_once(anchor)\n",
    "        e_p = self.forward_once(positive)\n",
    "        e_n = self.forward_once(negative)\n",
    "        return e_a, e_p, e_n\n",
    "\n",
    "class TripletDistillLoss(nn.Module):\n",
    "    def __init__(self, margin=0.3, alpha=0.7):\n",
    "        super().__init__()\n",
    "        self.margin = margin\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, s_a, s_p, s_n, t_a, t_p, t_n):\n",
    "        cos_ap = F.cosine_similarity(s_a, s_p)\n",
    "        cos_an = F.cosine_similarity(s_a, s_n)\n",
    "        triplet_loss = torch.clamp(cos_an - cos_ap + self.margin, min=0.0).mean()\n",
    "        distill_loss = ((1 - F.cosine_similarity(s_a, t_a)).mean() +\n",
    "                        (1 - F.cosine_similarity(s_p, t_p)).mean() +\n",
    "                        (1 - F.cosine_similarity(s_n, t_n)).mean()) / 3.0\n",
    "        return triplet_loss + self.alpha * distill_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7b10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_model = \"previously_trained_model.pt\"\n",
    "\n",
    "model = TripletNet(embedding_dim=256, pretrained=True)\n",
    "device = \"mps\"  \n",
    "model.load_state_dict(torch.load(prev_model, map_location=device))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b388af3",
   "metadata": {},
   "source": [
    "## Create semi-hard triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1baa549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 785 identities with images in both s1 and s2\n",
      "Total triplets: 785 -> train 549, val 117, test 119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 25/25 [00:58<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "splits = generate_triplets_from_folders(s1_dir, s2_dir, triplets_per_id=1)\n",
    "transform_eval  = get_eval_transforms(256)\n",
    "all_data = splits[\"train\"] + splits[\"val\"] + splits[\"test\"]\n",
    "dataset_test  = TripletDataset(all_data,  transform=transform_eval)\n",
    "loader_test  = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for a, p, n in tqdm(loader_test, desc=\"Testing\"):\n",
    "        a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "        e_a, e_p, e_n = model(a, p, n)\n",
    "        all_embeddings.append(e_a.cpu().numpy())\n",
    "        all_embeddings.append(e_p.cpu().numpy())\n",
    "\n",
    "all_embeddings = np.concatenate(all_embeddings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d809f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances(embeddings):\n",
    "    \"\"\"Compute pairwise squared Euclidean distances between embeddings.\"\"\"\n",
    "    dot_product = torch.matmul(embeddings, embeddings.t())\n",
    "    square_norm = torch.diag(dot_product)\n",
    "    distances = square_norm.unsqueeze(1) - 2 * dot_product + square_norm.unsqueeze(0)\n",
    "    distances = torch.clamp(distances, min=0.0)\n",
    "    return torch.sqrt(distances + 1e-8)\n",
    "\n",
    "def semi_hard_triplet_mining_multiple(embeddings, labels, margin=0.2, triplets_per_anchor=6):\n",
    "    \"\"\"\n",
    "    Offline semi-hard mining with multiple triplets per anchor.\n",
    "    - Anchor always from S1 (even indices)\n",
    "    - Positive from S2 (same ID)\n",
    "    - Negatives from S2 of different IDs\n",
    "    \"\"\"\n",
    "    device = embeddings.device\n",
    "    distances = pairwise_distances(embeddings)\n",
    "    triplets = []\n",
    "\n",
    "    num_embeddings = embeddings.shape[0]\n",
    "    for anchor_idx in range(0, num_embeddings, 2):  # only S1 anchors\n",
    "        anchor_label = labels[anchor_idx].item()\n",
    "        positive_idx = anchor_idx + 1\n",
    "\n",
    "        # all S2 indices for negatives\n",
    "        neg_indices = torch.arange(1, num_embeddings, 2, device=device)\n",
    "        neg_indices = neg_indices[labels[neg_indices] != anchor_label]\n",
    "\n",
    "        d_ap = distances[anchor_idx, positive_idx].item()\n",
    "\n",
    "        # semi-hard negatives: d_ap < d_an < d_ap + margin\n",
    "        semi_hard_negatives = neg_indices[\n",
    "            (distances[anchor_idx, neg_indices] > d_ap) &\n",
    "            (distances[anchor_idx, neg_indices] < d_ap + margin)\n",
    "        ]\n",
    "\n",
    "        # select up to `triplets_per_anchor` negatives\n",
    "        chosen_negatives = []\n",
    "\n",
    "        if len(semi_hard_negatives) >= triplets_per_anchor:\n",
    "            chosen_negatives = np.random.choice(semi_hard_negatives.cpu().numpy(),\n",
    "                                               triplets_per_anchor, replace=False)\n",
    "        else:\n",
    "            # use all semi-hard negatives\n",
    "            chosen_negatives = semi_hard_negatives.cpu().numpy().tolist()\n",
    "            if len(chosen_negatives) < triplets_per_anchor:\n",
    "                remaining = triplets_per_anchor - len(chosen_negatives)\n",
    "                hard_negatives = neg_indices[torch.argsort(distances[anchor_idx, neg_indices])]\n",
    "                for hn in hard_negatives.cpu().numpy():\n",
    "                    if hn not in chosen_negatives:\n",
    "                        chosen_negatives.append(hn)\n",
    "                    if len(chosen_negatives) == triplets_per_anchor:\n",
    "                        break\n",
    "\n",
    "        for n_idx in chosen_negatives:\n",
    "            triplets.append((anchor_idx, positive_idx, int(n_idx)))\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b58013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ids = n  # number of identities\n",
    "all_labels = []\n",
    "\n",
    "for i in range(num_ids):\n",
    "    all_labels.append(i)  # S1\n",
    "    all_labels.append(i)  # S2\n",
    "\n",
    "all_labels = torch.tensor(all_labels)  \n",
    "all_embeddings = torch.tensor(all_embeddings, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ed6aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4710 semi-hard triplets\n"
     ]
    }
   ],
   "source": [
    "semi_hard_triplets = semi_hard_triplet_mining_multiple(all_embeddings, all_labels, margin=0.2, triplets_per_anchor=6)\n",
    "print(f\"Generated {len(semi_hard_triplets)} semi-hard triplets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5196d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_images = sorted(glob.glob(os.path.join(s1_dir, \"*\")))\n",
    "s2_images = sorted(glob.glob(os.path.join(s2_dir, \"*\")))\n",
    "interleaved = [val for pair in zip(s1_images, s2_images) for val in pair]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a739d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4710 triplets with paths\n"
     ]
    }
   ],
   "source": [
    "triplet_paths = []\n",
    "for a_idx, p_idx, n_idx in semi_hard_triplets:\n",
    "    anchor_path   = interleaved[a_idx]\n",
    "    positive_path = interleaved[p_idx]\n",
    "    negative_path = interleaved[n_idx]\n",
    "    triplet_paths.append((anchor_path, positive_path, negative_path))\n",
    "\n",
    "print(f\"Generated {len(triplet_paths)} triplets with paths\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06219edb",
   "metadata": {},
   "source": [
    "## Dataset creation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a49d34fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train triplets: 3297, Val triplets: 706, Test triplets: 707\n"
     ]
    }
   ],
   "source": [
    "# Shuffle all triplets\n",
    "random.seed(42)\n",
    "random.shuffle(triplet_paths)\n",
    "\n",
    "split = (0.7, 0.15, 0.15)\n",
    "n = len(triplet_paths)\n",
    "n_train = int(split[0] * n)\n",
    "n_val   = int(split[1] * n)\n",
    "\n",
    "train_triplets = triplet_paths[:n_train]\n",
    "val_triplets   = triplet_paths[n_train:n_train+n_val]\n",
    "test_triplets  = triplet_paths[n_train+n_val:]\n",
    "\n",
    "print(f\"Train triplets: {len(train_triplets)}, Val triplets: {len(val_triplets)}, Test triplets: {len(test_triplets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478cec25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1570, 256)\n"
     ]
    }
   ],
   "source": [
    "transform_train = get_train_transforms(512)\n",
    "transform_eval  = get_eval_transforms(512)\n",
    "\n",
    "teacher_embeddings1 = np.load(\"<path_to_session1_teacher_emb>\")\n",
    "teacher_embeddings2 = np.load(\"<path_to_session1_teacher_emb>\")\n",
    "\n",
    "teacher_embeddings = np.concatenate([teacher_embeddings1, teacher_embeddings2], axis=1)\n",
    "pca = PCA(n_components=256)\n",
    "teacher_embeddings_256 = pca.fit_transform(teacher_embeddings1)  # [num_samples, 256]\n",
    "\n",
    "dataset_train = TripletDatasetWithTeacher(train_triplets, s1_dir, s2_dir, teacher_embeddings_256, transform=transform_train)\n",
    "dataset_val   = TripletDatasetWithTeacher(val_triplets, s1_dir, s2_dir, teacher_embeddings_256,   transform=transform_eval)\n",
    "dataset_test  = TripletDatasetWithTeacher(test_triplets,  s1_dir, s2_dir, teacher_embeddings_256, transform=transform_eval)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=16, shuffle=True, num_workers=0, drop_last=True)\n",
    "loader_val   = DataLoader(dataset_val, batch_size=32, shuffle=False, num_workers=0, drop_last=False)\n",
    "loader_test  = DataLoader(dataset_test, batch_size=32, shuffle=False, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train contains 3297 triplets (anchor, positive, negative)\n",
      "Validation contains 706 triplets (anchor, positive, negative)\n",
      "Test contains 707 triplets (anchor, positive, negative)\n"
     ]
    }
   ],
   "source": [
    "def print_triplet_distribution(dataset, name=\"Dataset\"):\n",
    "    n = len(dataset)\n",
    "    print(f\"{name} contains {n} triplets (anchor, positive, negative)\")\n",
    "\n",
    "# Print distributions\n",
    "print_triplet_distribution(dataset_train, \"Train\")\n",
    "print_triplet_distribution(dataset_val, \"Validation\")\n",
    "print_triplet_distribution(dataset_test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bbfe4",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "def train_triplet_distill(model, train_loader, val_loader, device,\n",
    "                           epochs=30, lr=1e-4, weight_decay=1e-5,\n",
    "                           margin=0.3, alpha=0.7):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "    criterion = TripletDistillLoss(margin=margin, alpha=alpha)\n",
    "    best_auc = 0.0\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for a, p, n, t_a, t_p, t_n in tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs} [Train]\"):\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            t_a, t_p, t_n = t_a.to(device), t_p.to(device), t_n.to(device)\n",
    "\n",
    "            s_a, s_p, s_n = model(a, p, n)\n",
    "            loss = criterion(s_a, s_p, s_n, t_a, t_p, t_n)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * a.size(0)\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss_total = 0.0\n",
    "        with torch.no_grad():\n",
    "            for a, p, n, t_a, t_p, t_n in tqdm(val_loader, desc=f\"Epoch {epoch}/{epochs} [Val]\"):\n",
    "                a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "                t_a, t_p, t_n = t_a.to(device), t_p.to(device), t_n.to(device)\n",
    "\n",
    "                s_a, s_p, s_n = model(a, p, n)\n",
    "                val_loss = criterion(s_a, s_p, s_n, t_a, t_p, t_n)\n",
    "                val_loss_total += val_loss.item() * a.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss_total / len(val_loader.dataset)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        val_auc = evaluate_triplet_auc_with_teacher(model, val_loader, device)\n",
    "\n",
    "        scheduler.step(val_auc)\n",
    "        print(f\"Epoch {epoch:03d} | TrainLoss={avg_train_loss:.4f} | ValLoss={avg_val_loss:.4f} | ValAUC={val_auc:.4f}\")\n",
    "\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            torch.save(model.state_dict(), \"<save_model_path>.pt\")\n",
    "            print(\"saved best model\")\n",
    "\n",
    "    print(\"Training complete. Best AUC:\", best_auc)\n",
    "\n",
    "\n",
    "def evaluate_triplet_auc_with_teacher(model, loader, device):\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for a, p, n, t_a, t_p, t_n in loader:\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            e_a, e_p, e_n = model(a, p, n)\n",
    "\n",
    "            # positive pairs\n",
    "            sim_pos = F.cosine_similarity(e_a, e_p).cpu().numpy()\n",
    "            labels.extend([1]*len(sim_pos))\n",
    "            scores.extend(sim_pos.tolist())\n",
    "\n",
    "            # negative pairs\n",
    "            sim_neg = F.cosine_similarity(e_a, e_n).cpu().numpy()\n",
    "            labels.extend([0]*len(sim_neg))\n",
    "            scores.extend(sim_neg.tolist())\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(np.array(labels), np.array(scores))\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df39264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\"  # mention your gpu or cpu\n",
    "model = TripletNet(embedding_dim=256, pretrained=True)\n",
    "\n",
    "train_triplet_distill(\n",
    "    model,\n",
    "    train_loader=loader_train,\n",
    "    val_loader=loader_val,\n",
    "    device=device,\n",
    "    epochs=30,\n",
    "    lr=1e-4,\n",
    "    margin=0.6,\n",
    "    alpha=0.01  # weight for distillation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d4faca",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, train_losses, '-', label='Train Loss', color='blue')\n",
    "plt.plot(epochs, val_losses, '-', label='Validation Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f78417",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73973073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_triplet_cosine(model, loader_test, device):\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(\"<save_model_path>.pt\", map_location=device))\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    labels = []\n",
    "    scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a, p, n in tqdm(loader_test, desc=\"Testing\"):\n",
    "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
    "            e_a, e_p, e_n = model(a, p, n)\n",
    "\n",
    "            # Cosine similarity for positive (anchor-positive) pairs\n",
    "            sim_pos = F.cosine_similarity(e_a, e_p).cpu().numpy()\n",
    "            labels.extend([1] * len(sim_pos))\n",
    "            scores.extend(sim_pos.tolist())\n",
    "\n",
    "            # Cosine similarity for negative (anchor-negative) pairs\n",
    "            sim_neg = F.cosine_similarity(e_a, e_n).cpu().numpy()\n",
    "            labels.extend([0] * len(sim_neg))\n",
    "            scores.extend(sim_neg.tolist())\n",
    "\n",
    "    labels = np.array(labels)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    #  Compute metrics \n",
    "    try:\n",
    "        auc_val = roc_auc_score(labels, scores)\n",
    "    except:\n",
    "        auc_val = 0.5\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    fnr = 1 - tpr\n",
    "    eer_idx = np.nanargmin(np.abs(fnr - fpr))\n",
    "    eer = (fpr[eer_idx] + fnr[eer_idx]) / 2.0\n",
    "    thresh = thresholds[eer_idx]\n",
    "\n",
    "    preds = (scores >= thresh).astype(int)\n",
    "    acc = np.mean(preds == labels)\n",
    "\n",
    "    # Print metrics\n",
    "    print(\"\\n========== TEST RESULTS ==========\")\n",
    "    print(f\"AUC:       {auc_val:.4f}\")\n",
    "    print(f\"EER:       {eer*100:.2f}%\")\n",
    "    # print(f\"Thr@EER:   {thresh:.4f}\")\n",
    "    print(f\"Accuracy:  {acc*100:.2f}%\")\n",
    "    print(\"=================================\\n\")\n",
    "\n",
    "    # Plot ROC\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(fpr, tpr, label=f\"ROC (AUC={auc_val:.4f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Test ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return auc_val, eer, acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TripletNet(embedding_dim=256, pretrained=True)\n",
    "device = \"mps\"  \n",
    "auc_val, eer, acc, df_preds = test_triplet_cosine(model, loader_test, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab86042",
   "metadata": {},
   "source": [
    "# Contact Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11337b23",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dcdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContactTripletDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        #  Load files and group by ID -> would change accoridng to your naming\n",
    "        self.id_to_images = {}  # { \"1\": [\"1_1.tif\", \"1_2.tif\"], ... }\n",
    "\n",
    "        for fname in sorted(os.listdir(root_dir)):\n",
    "            if not (fname.lower().endswith(\".tif\") or fname.lower().endswith(\".png\")):\n",
    "                continue\n",
    "\n",
    "            parts = fname.split(\"_\")\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "\n",
    "            id_str = parts[0]  \n",
    "            self.id_to_images.setdefault(id_str, []).append(fname)\n",
    "\n",
    "        self.ids = list(self.id_to_images.keys())\n",
    "\n",
    "        # Filter: only IDs with >=2 images can produce anchor + positive\n",
    "        self.ids = [id_ for id_ in self.ids if len(self.id_to_images[id_]) >= 2]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids) * 3  # arbitrary multiplier for more triplets\n",
    "\n",
    "    def load_image(self, path):\n",
    "        img = Image.open(path).convert(\"L\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #  Choose anchor ID \n",
    "        anchor_id = random.choice(self.ids)\n",
    "        imgs = self.id_to_images[anchor_id]\n",
    "\n",
    "        anchor_name, positive_name = random.sample(imgs, 2)\n",
    "\n",
    "        neg_id = random.choice([i for i in self.ids if i != anchor_id])\n",
    "        neg_name = random.choice(self.id_to_images[neg_id])\n",
    "\n",
    "        # Load images\n",
    "        anchor = self.load_image(os.path.join(self.root_dir, anchor_name))\n",
    "        positive = self.load_image(os.path.join(self.root_dir, positive_name))\n",
    "        negative = self.load_image(os.path.join(self.root_dir, neg_name))\n",
    "\n",
    "        return anchor, positive, negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf273f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContactlessTripletDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Creates triplets from two directories:\n",
    "        dir1 = S1 images\n",
    "        dir2 = S2 images\n",
    "    Filenames must match: e.g., P10_LF2.tif in both dirs.\n",
    "    \n",
    "    Anchor  = img from S1\n",
    "    Positive = matching img from S2\n",
    "    Negative = img from S2 but from DIFFERENT person (different PXX)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dir1, dir2, transform=None):\n",
    "        self.dir1 = dir1\n",
    "        self.dir2 = dir2\n",
    "        self.transform = transform\n",
    "\n",
    "        exts = (\".tif\", \".tiff\", \".png\", \".bmp\", \".jpg\")\n",
    "\n",
    "        # load & sort\n",
    "        files1 = [\n",
    "            f for f in os.listdir(dir1)\n",
    "            if f.lower().endswith(exts)\n",
    "        ]\n",
    "        files1 = sorted(files1)\n",
    "\n",
    "        # store valid pairs\n",
    "        self.pairs = []   # list of (id_string, path_S1, path_S2)\n",
    "\n",
    "        for fname in files1:\n",
    "            f1 = os.path.join(dir1, fname)\n",
    "            f2 = os.path.join(dir2, fname)\n",
    "\n",
    "            if os.path.exists(f2):\n",
    "                id_name = os.path.splitext(fname)[0]\n",
    "                self.pairs.append((id_name, f1, f2))\n",
    "\n",
    "        # group by ID for sampling\n",
    "        # ID = P<number>\n",
    "        self.id_to_indices = {}   # { \"P10\": [idx1, idx2, ...] }\n",
    "\n",
    "        for idx, (id_name, f1, f2) in enumerate(self.pairs):\n",
    "            # extract \"P10\" out of \"P10_LF2\"\n",
    "            base_id = id_name.split(\"_\")[0]\n",
    "            self.id_to_indices.setdefault(base_id, []).append(idx)\n",
    "\n",
    "        self.ids = list(self.id_to_indices.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def _load_grayscale(self, path):\n",
    "        img = Image.open(path)\n",
    "        arr = np.array(img)\n",
    "        arr = np.clip(arr, 0, 1)  \n",
    "        arr = (arr * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(arr, mode='L')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Anchor and Positive pair (S1–S2 matching)\n",
    "        id_name, f1, f2 = self.pairs[index]\n",
    "\n",
    "        # parse person ID\n",
    "        anchor_id = id_name.split(\"_\")[0]\n",
    "\n",
    "        anchor = self._load_grayscale(f1)\n",
    "        positive = self._load_grayscale(f2)\n",
    "\n",
    "        # Negative Sampling\n",
    "        neg_id = random.choice([i for i in self.ids if i != anchor_id])\n",
    "        neg_idx = random.choice(self.id_to_indices[neg_id])\n",
    "\n",
    "        _, _, neg_path = self.pairs[neg_idx]  \n",
    "        negative = self._load_grayscale(neg_path)\n",
    "\n",
    "        return anchor, positive, negative\n",
    "\n",
    "def get_eval_transforms(img_size=512):\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51ceae",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = get_eval_transforms(512)\n",
    "dataset = ContactTripletDataset(\"<your_path>\", transform=trans)\n",
    "dataset_cl = ContactlessTripletDataset(\"<your_s1_path>\", \"<your_s2_path>\", transform=trans)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "loader_cl = DataLoader(dataset_cl, batch_size=8, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739a680",
   "metadata": {},
   "source": [
    "### Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf194911",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = TripletNet(embedding_dim=256, pretrained=True).to(device)\n",
    "teacher.load_state_dict(torch.load(\"<load_pt_path>\"))\n",
    "\n",
    "for p in teacher.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "teacher.eval()   # freeze completely\n",
    "for name, p in teacher.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ca88ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = TripletNet(embedding_dim=256, pretrained=True).to(device)\n",
    "student.load_state_dict(torch.load(\"<load_pt_path>\"))\n",
    "# freeze everything first\n",
    "for name, p in student.named_parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Unfreeze as required\n",
    "for idx in [0, 1, 2, 3]:\n",
    "    for p in student.backbone[idx].parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "for i in range(4):\n",
    "    student.backbone[i].train()\n",
    "for i in range(4,8):\n",
    "    student.backbone[i].eval()\n",
    "student.head.eval()\n",
    "for name, p in student.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee9f531",
   "metadata": {},
   "source": [
    "### Finetune Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0158ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=0.4, p=2) \n",
    "lambda_distill = 0.9   \n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, student.parameters()),\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-5\n",
    ")\n",
    "contactless_loader = loader_cl\n",
    "contact_loader = loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad58e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "\n",
    "    contactless_iter = iter(contactless_loader)\n",
    "\n",
    "    for anchor, pos, neg in tqdm(contact_loader):\n",
    "\n",
    "        # 1. Forward on student\n",
    "        anchor = anchor.to(device)\n",
    "        pos = pos.to(device)\n",
    "        neg = neg.to(device)\n",
    "        e_a, e_p, e_n = student(anchor, pos, neg)\n",
    "\n",
    "        loss_triplet = triplet_loss(e_a, e_p, e_n)\n",
    "\n",
    "        # 2. Get a batch of contactless and compute distillation loss\n",
    "        try:\n",
    "            cl_imgs, _, _ = next(contactless_iter)\n",
    "        except StopIteration:\n",
    "            contactless_iter = iter(contactless_loader)\n",
    "            cl_imgs, _, _ = next(contactless_iter)\n",
    "\n",
    "        cl_imgs = cl_imgs.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_emb = teacher.forward_once(cl_imgs)\n",
    "\n",
    "        student_emb = student.forward_once(cl_imgs)\n",
    "        loss_distill = mse_loss(student_emb, teacher_emb)\n",
    "\n",
    "        # 3. Total loss\n",
    "        loss =  loss_triplet + lambda_distill * loss_distill\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Loss = {total_loss/len(contact_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba01ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.state_dict(), \"<save_path>.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
