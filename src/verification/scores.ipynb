{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d756332a",
   "metadata": {},
   "source": [
    "# Verifinger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f1fcf",
   "metadata": {},
   "source": [
    "We used the Verifinger SDK (free downloadable version) available at - https://www.neurotechnology.com/download.html#demo, so download it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585862ac",
   "metadata": {},
   "source": [
    "### Step 1: Generate Score Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea08a8c",
   "metadata": {},
   "source": [
    "1. To enable permissions run- `chmod +x FingersAlgorithmDemo.app`\n",
    "\n",
    "2. Then we run the FingersAlgorithmDemo.app executable\n",
    "\n",
    "    For Linux:\n",
    "   `./FingersAlgorithmDemo` or \n",
    "\n",
    "    For Mac:\n",
    "    `open FingersAlgorithmDemo.app`\n",
    "\n",
    "3. First we enrolled our Session1 data.\n",
    "\n",
    "4. Then we ran a script to obtain score_matrix of matching Session1 with Session2 by performing identification with each possible combination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c16c6f",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Match Scores & Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee15ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ec74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scores(data_path):\n",
    "    scores_matrix = []\n",
    "    with open(f\"{data_path}/scores_matrix.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            row = list(map(int, line.strip().split(\",\")))\n",
    "            scores_matrix.append(row)\n",
    "    scores_matrix = np.array(scores_matrix)\n",
    "\n",
    "    genuine_scores = np.diag(scores_matrix)\n",
    "    genuine_scores = np.array(genuine_scores)\n",
    "\n",
    "    imposter_scores = []\n",
    "    used_pairs = set()\n",
    "\n",
    "    while len(imposter_scores) < 1000:\n",
    "        i, j = np.random.randint(0, 100, 2)\n",
    "        if i != j and (i, j) not in used_pairs:\n",
    "            imposter_scores.append(scores_matrix[i][j])\n",
    "            used_pairs.add((i, j))\n",
    "                \n",
    "    imposter_scores = np.array(imposter_scores) \n",
    "\n",
    "    return genuine_scores, imposter_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79eb5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_arrays(data_path):\n",
    "    genuine_scores, imposter_scores = load_scores(data_path)\n",
    "\n",
    "    min_score = min(genuine_scores.min(), imposter_scores.min())\n",
    "    max_score = max(genuine_scores.max(), imposter_scores.max())\n",
    "    thresholds = np.arange(min_score, max_score, 5)\n",
    "\n",
    "    # Initialize metrics\n",
    "    FAR = []  # False Acceptance Rate\n",
    "    FRR = []  # False Rejection Rate\n",
    "    TPR = []  # True Positive Rate    \n",
    "    FPR = []  # False Positive Rate\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        false_rejects = sum(score < threshold for score in genuine_scores)\n",
    "        true_accepts = sum(score >= threshold for score in genuine_scores)\n",
    "        \n",
    "        false_accepts = sum(score >= threshold for score in imposter_scores)\n",
    "        true_rejects = sum(score < threshold for score in imposter_scores)\n",
    "        \n",
    "        FAR.append(false_accepts / len(imposter_scores))\n",
    "        FRR.append(false_rejects / len(genuine_scores))\n",
    "        TPR.append(true_accepts / len(genuine_scores))\n",
    "        FPR.append(false_accepts / len(imposter_scores))\n",
    "\n",
    "    return np.array(thresholds), np.array(FAR), np.array(FRR), np.array(TPR), np.array(FPR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afdfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(ocr_paths, labels=[None, None, None], colors=['blue', 'green', 'orange']):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    for ocr_path, label, color in zip(ocr_paths, labels, colors):\n",
    "        thresholds, FAR, FRR, TPR, FPR = compute_arrays(ocr_path)\n",
    "        roc_auc = auc(FPR, TPR)\n",
    "        \n",
    "        plt.plot(FPR, TPR, color=color, lw=2,\n",
    "                 label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1.2)\n",
    "\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Acceptance Rate (FAR)', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "\n",
    "    plt.legend(loc='lower right', fontsize=13, frameon=True)\n",
    "    plt.grid(linestyle='--', alpha=0.4)\n",
    "\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc589cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_far_frr(ocr_paths, titles, colors=['blue', 'green', 'orange']):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    for i in range(len(ocr_paths)):\n",
    "        thresholds, FAR, FRR, TPR, FPR = compute_arrays(ocr_paths[i])\n",
    "        eer_index = np.argmin(np.abs(FAR - FRR))\n",
    "        eer_threshold = thresholds[eer_index]\n",
    "        EER = (FAR[eer_index] + FRR[eer_index]) / 2\n",
    "\n",
    "        plt.plot(FRR, FAR, label=f\"{titles[i]} (EER={EER:.2f})\", color=colors[i])\n",
    "\n",
    "        plt.scatter(FRR[eer_index], FAR[eer_index],\n",
    "                    s=40, color=colors[i], marker=\"o\", edgecolor='k', zorder=5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.4)\n",
    "\n",
    "    plt.scatter([], [], s=40, color=\"white\", edgecolor=\"k\", label=\"EER point\")\n",
    "\n",
    "    plt.xlabel(\"False Rejection Rate (FRR)\", fontsize=14)\n",
    "    plt.ylabel(\"False Acceptance Rate (FAR)\", fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.legend(fontsize=13, loc=\"upper right\", frameon=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072e255",
   "metadata": {},
   "source": [
    "# DeepPrint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e71097",
   "metadata": {},
   "source": [
    "We used the DeepPrint Library code available at - https://github.com/tim-rohwedder/fixed-length-fingerprint-extractors, so clone the repository to run the below code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101285e3",
   "metadata": {},
   "source": [
    "### Step 1: Generate Embeddings\n",
    "\n",
    "We slightly changed their library code to allow recognition of our dataset of .tif images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33842086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from flx.data.image_loader import ImageLoader\n",
    "import torch\n",
    "import torchvision.transforms.functional as VTF\n",
    "import PIL\n",
    "from IPython.display import display\n",
    "import os\n",
    "from flx.extractor.fixed_length_extractor import get_DeepPrint_Tex, get_DeepPrint_TexMinu, DeepPrintExtractor\n",
    "from flx.data.dataset import *\n",
    "from flx.data.image_loader import SFingeLoader\n",
    "from flx.data.transformed_image_loader import TransformedImageLoader\n",
    "from flx.image_processing.binarization import LazilyAllocatedBinarizer\n",
    "from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size\n",
    "from flx.data.embedding_loader import EmbeddingLoader\n",
    "from flx.benchmarks.matchers import CosineSimilarityMatcher\n",
    "from flx.scripts.generate_benchmarks import create_verification_benchmark\n",
    "from sklearn.metrics import auc\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a45063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load the pre-trained model parameters use num_training_subjects=8000\n",
    "extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(num_training_subjects=8000, num_dims=256)\n",
    "\n",
    "# To load the pre-trained model parameters use\n",
    "MODEL_DIR: str = os.path.abspath(\"<MODEL>\") # Path to the directory containing the model parameters\n",
    "extractor.load_best_model(MODEL_DIR)\n",
    "\n",
    "DATASET_PATH: str = os.path.abspath(\"<DATASET>\")\n",
    "\n",
    "# We will use the SFingeLoader to load the images from the dataset\n",
    "image_loader = TransformedImageLoader(\n",
    "        images=SFingeLoader(DATASET_PATH),\n",
    "        poses=None,\n",
    "        transforms=[\n",
    "            LazilyAllocatedBinarizer(5.0),\n",
    "            pad_and_resize_to_deepprint_input_size,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "image_dataset: Dataset = Dataset(image_loader, image_loader.ids)\n",
    "\n",
    "texture_embeddings, minutia_embeddings = extractor.extract(image_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d81538",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_embeddings.save(\"embeddings/<DATAPATH>_texture_emb\")\n",
    "minutia_embeddings.save(\"embeddings/<DATAPATH>_minutia_emb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c506543",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Match Scores & Plot\n",
    "\n",
    "Now we load the embeddings and calculate match scores and plot ROC and FARvsFRR Curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d59e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD DATASET\n",
    "\n",
    "def load_dataset(path: str) -> Dataset:\n",
    "    \"\"\"Load the dataset from the given path.\"\"\"\n",
    "    DATASET_PATH: str = os.path.abspath(\"<DATASET>\"+path)\n",
    "    # We will use the SFingeLoader to load the images from the dataset\n",
    "    image_loader = TransformedImageLoader(\n",
    "            images=SFingeLoader(DATASET_PATH),\n",
    "            poses=None,\n",
    "            transforms=[\n",
    "                LazilyAllocatedBinarizer(5.0),\n",
    "                pad_and_resize_to_deepprint_input_size,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    image_dataset: Dataset = Dataset(image_loader, image_loader.ids)\n",
    "    return image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa8cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD EMBEDDINGS\n",
    "\n",
    "def load_embeddings(path: str) -> EmbeddingLoader:\n",
    "    texture_embeddings = EmbeddingLoader.load(f\"embeddings/{path}_texture_emb\")\n",
    "    minutia_embeddings = EmbeddingLoader.load(f\"embeddings/{path}_minutia_emb\")\n",
    "    return texture_embeddings, minutia_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6effe376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(path: str):\n",
    "    image_dataset = load_dataset(path)\n",
    "    texture_embeddings, minutia_embeddings = load_embeddings(path)\n",
    "    embeddings = EmbeddingLoader.combine(texture_embeddings, minutia_embeddings)\n",
    "    matcher = CosineSimilarityMatcher(EmbeddingLoader.combine(texture_embeddings, minutia_embeddings))\n",
    "    # Can change mode of verifier\n",
    "    # matcher = CosineSimilarityMatcher(texture_embeddings)\n",
    "    # matcher = CosineSimilarityMatcher(minutia_embeddings)\n",
    "\n",
    "    NUM_IMPRESSIONS_PER_SUBJECT = 2 # Can modify according to how many images have been captured\n",
    "    benchmark = create_verification_benchmark(\n",
    "    subjects=list(range(image_dataset.num_subjects)),\n",
    "    impressions_per_subject=list(range(NUM_IMPRESSIONS_PER_SUBJECT)))\n",
    "\n",
    "    results = benchmark.run(matcher)\n",
    "\n",
    "    genuine_scores = results.get_mated_scores()\n",
    "    imposter_scores = results.get_non_mated_scores()\n",
    "\n",
    "    return genuine_scores, imposter_scores, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c89177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_arrays(genuine_scores, imposter_scores):\n",
    "    min_score = min(genuine_scores.min(), imposter_scores.min())\n",
    "    max_score = max(genuine_scores.max(), imposter_scores.max())\n",
    "    thresholds = np.linspace(min_score, max_score, num=100)\n",
    "\n",
    "    FAR = []  # False Acceptance Rate\n",
    "    FRR = []  # False Rejection Rate\n",
    "    TPR = []  # True Positive Rate    \n",
    "    FPR = []  # False Positive Rate\n",
    "\n",
    "    for threshold in thresholds:\n",
    "        false_rejects = sum(score < threshold for score in genuine_scores)\n",
    "        true_accepts = sum(score >= threshold for score in genuine_scores)\n",
    "        \n",
    "        false_accepts = sum(score >= threshold for score in imposter_scores)\n",
    "        true_rejects = sum(score < threshold for score in imposter_scores)\n",
    "        \n",
    "        FAR.append(false_accepts / len(imposter_scores))\n",
    "        FRR.append(false_rejects / len(genuine_scores))\n",
    "        TPR.append(true_accepts / len(genuine_scores))\n",
    "        FPR.append(false_accepts / len(imposter_scores))\n",
    "\n",
    "    return np.array(thresholds), np.array(FAR), np.array(FRR), np.array(TPR), np.array(FPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce976d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curves(ocr_paths, labels=None, colors=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    for ocr_path, label, color in zip(ocr_paths, labels, colors):\n",
    "        genuine_scores, imposter_scores, results = get_scores(ocr_path)\n",
    "        thresholds, FAR, FRR, TPR, FPR = compute_arrays(genuine_scores, imposter_scores)\n",
    "        roc_auc = auc(FPR, TPR)\n",
    "        plt.plot(FPR, TPR, color=color, lw=2,\n",
    "                 label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', lw=1.2)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel('False Acceptance Rate (FAR)', fontsize=14)\n",
    "    plt.ylabel('True Positive Rate (TPR)', fontsize=14)\n",
    "    plt.legend(loc='lower right', fontsize=13, frameon=True)\n",
    "    plt.grid(linestyle='--', alpha=0.4)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_far_frr(ocr_paths, titles, colors=None):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(len(ocr_paths)):\n",
    "        genuine_scores, imposter_scores, results = get_scores(ocr_paths[i])\n",
    "        thresholds, FAR, FRR, TPR, FPR = compute_arrays(genuine_scores, imposter_scores)\n",
    "\n",
    "        eer_index = np.argmin(np.abs(FAR - FRR))\n",
    "        eer_threshold = thresholds[eer_index]\n",
    "        EER = (FAR[eer_index] + FRR[eer_index]) / 2\n",
    "\n",
    "        plt.plot(FRR, FAR, label=f\"{titles[i]} (EER={EER:.2f})\", color=colors[i])\n",
    "\n",
    "        plt.scatter(FRR[eer_index], FAR[eer_index],\n",
    "                    s=40, color=colors[i], marker=\"o\", edgecolor='k', zorder=5)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], 'k--', alpha=0.4)\n",
    "\n",
    "    plt.scatter([], [], s=40, color=\"white\", edgecolor=\"k\", label=\"EER point\")\n",
    "\n",
    "    plt.xlabel(\"False Rejection Rate (FRR)\", fontsize=14)\n",
    "    plt.ylabel(\"False Acceptance Rate (FAR)\", fontsize=14)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.legend(fontsize=13, loc=\"upper right\", frameon=True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
